{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6378b578",
   "metadata": {},
   "source": [
    "# (15 December) Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4e5c3",
   "metadata": {},
   "source": [
    "##### Assume that logistic regression is a regression problem because it has the word in it\n",
    "##### But actually it is not a regression problem but it is a CLASSIFICATION problem\n",
    "##### So the dependent or target variable is categorical but not numerical\n",
    "##### It is supervised learning (i.e. has labels)\n",
    "##### Logisitic regression only works well with linear problems and hence this is not used in the industry either\n",
    "##### For logistic regression --> We use a SIGMOID CURVE (f(y) = 1/(1 + e^(-y)) where y=mx+c\n",
    "##### y ranges from -infinity to +infinity \n",
    "##### f(y) ranges from 0 to 1, therefore in logistic regresion, answer ranges from 0 to 1\n",
    "##### But in linear regression, answer ranges from -infinity to +infinity\n",
    "##### It is an s-shaped curve\n",
    "##### Whereas in linear regression --> we use a straight line and y=mx+c (as discussed before)\n",
    "##### It is converted into a classification problem when based on answer we are putting it in different categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e1bae",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3244d",
   "metadata": {},
   "source": [
    "##### Took examples of a model guessing if cat or not\n",
    "##### Find prediction from model and compare with actual truth.\n",
    "##### eg: cat -> +ve; not a cat -> -ve [FIRST, define what is positive and the opposite as negative]\n",
    "##### True positive (TP) -> prediction is +ve (cat) and actual is also +ve (cat)\n",
    "##### True negative (TN) -> prediction is -ve (not a cat) and actual is also -ve (not a cat) \n",
    "##### False positive (FP) -> prediction is +ve (cat) and actual is -ve (not a cat)\n",
    "##### False negative (FN) -> prediction is -ve (not a cat) and actual is +ve (cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349dc7dc",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f60c51",
   "metadata": {},
   "source": [
    "##### Confusion matrix (CM):\n",
    "##### P -> Predicted\n",
    "##### A -> Actual\n",
    "##### A (row), P (column) (eg:)\n",
    "##### can be actual or predicted; we just have to fill the table\n",
    "#####  0 -> negative; 1->positive\n",
    "#####  -  1  0\n",
    "#####  0 FP TN\n",
    "#####  1 TP FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397bda5",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12f006",
   "metadata": {},
   "source": [
    "##### Accuracy: (A)\n",
    "##### correct/total\n",
    "##### A = (TP+TN) / (TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6b909",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc00066",
   "metadata": {},
   "source": [
    "##### Recall: (R)\n",
    "##### out of actual positives, how many are true\n",
    "##### R = TP / (TP+FN) (FN because actually it is true but model predicted false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d844d2",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d58fd3",
   "metadata": {},
   "source": [
    "##### Precision: (P)\n",
    "##### out of predicted positives, how many are true\n",
    "##### R = TP / (TP+FP) (FP because we predicted positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098aa06e",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25860dc3",
   "metadata": {},
   "source": [
    "##### Practical part: \n",
    "##### drop those attributes which don't affect the model\n",
    "##### Should be able to:\n",
    "##### 1. import np,pd,sb and matplotlib\n",
    "##### 2. Load the dataset\n",
    "##### 3. Display top 5 rows\n",
    "##### 4. Descriptive statistics (just df.describe())\n",
    "##### 5. Code for info\n",
    "##### 6. Code for dtypes\n",
    "##### 7. Code for missing values?\n",
    "##### Dropped the cabin column because out of 891 values; 687 values are null; so in the method of missing values; it is not a good idea here to replace it with the median of all other (891-687) values as normally done.\n",
    "##### Dependent variable \"survived: is categorical but represented as numerical so classification task only (logistic)\n",
    "##### Survived - 1; not survived - 0\n",
    "##### Same case with Pclass\n",
    "##### We use mean, median and mode to replace the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35948ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Stopped with encoding; next class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
