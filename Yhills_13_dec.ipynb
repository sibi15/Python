{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e5d0ed",
   "metadata": {},
   "source": [
    "# (13 December) Linear Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff692ea",
   "metadata": {},
   "source": [
    "##### Linear Regression is a model in machine learning\n",
    "##### Not used in industry but is the basic algorithm for everything else\n",
    "##### Mostly this is asked in interviews and stuff\n",
    "##### Example of pens and pencils prices\n",
    "##### Related to linear regression by forming a relationship between dependent and independent variables\n",
    "##### Should only be 1 dependent variable (DV) and any number of independent variables (IV) in a problem\n",
    "##### 1 DV & 1 IDV -> Simple Linear Regression\n",
    "##### 1 DV & multiple IDV -> Multiple Linear Regression\n",
    "##### In a regression problem, dependent variable is always numerical\n",
    "##### In a classification problem, dependent variable is always categorical\n",
    "##### We depend on machine learning when there are many attributes (rows and columns) and data is not linear\n",
    "##### This is why linear regression is not used in industry; never face any linear problems; always non-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0018ec",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2725bc",
   "metadata": {},
   "source": [
    "##### > Linear Regression:\n",
    "##### Firstly, random guess: is made (if actual y=5x (y); random guess can be y=3x (y hat); separate column is made\n",
    "##### Secondly, find error: we need to find the difference and square it: (y - yhat)^2 ; add another column; sum errors and find mean\n",
    "##### Thirdly, another guess (find direction where error is getting minimised): eg: y=2x or y=4x from original y=5x\n",
    "##### Keep doing this until eventually error = 0; next will be y=4.1x or y=4.2x\n",
    "##### 1. Goal is  (mean square error) => [sigma (y-y hat)^2] / n = 0 (MSE)\n",
    "##### Many ways of calculating errors;\n",
    "##### Ways or metrics to evaluate the performance of the model (proof)\n",
    "##### 2. Mean Absolute Error ==> [sigma modulus ((y-y hat)) ] / n = 0 (MAE)\n",
    "##### 3. Root Mean Square Error (RMSE) ==> root (MSE)\n",
    "##### 4. R^2 = 1 - [ - 1/n (sigma (y-yhat)^2)) / (1/n (sigma (y-ybar)^2)) ] => numerator -> MSE (yhat -> guess); denominator -> variance (ybar -> mean)\n",
    "##### R^2 -> is how much variance is explained by the model: good model as R^2 gets closer to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b580a33",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac0fc7",
   "metadata": {},
   "source": [
    "\n",
    "##### Linear in graph; connect points; from straight line (y=mx+c); find slope (m=y2-y1/x2-x1)\n",
    "##### Non-linear in graph: Connect with a straight line as many points as possible\n",
    "##### Find error as: eg: 5 points -> (y1-y1bar)^2 + (y2-y2bar)^2 + ... + (y5-y5bar)^2 and find mean; slope as well\n",
    "##### Now come up with another straight line\n",
    "##### Infinite lines can be drawn\n",
    "##### Line which gives the minimum error is called the best fit line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6d495",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629f9a1",
   "metadata": {},
   "source": [
    "##### Rest of class done in the linear_progression_copy_2 file; also in github; taken from Premalatha-success niit_repository"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
